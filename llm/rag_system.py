"""
RAG ì‹œìŠ¤í…œ - Gemini Embeddings API ì‚¬ìš© (ë©”ëª¨ë¦¬ ìµœì í™”)
"""
import os
from pathlib import Path
from typing import List, Dict
from langchain_google_genai import GoogleGenerativeAIEmbeddings  # â† Gemini!
from langchain_community.vectorstores import FAISS
from langchain_text_splitters import RecursiveCharacterTextSplitter
import pdfplumber

# í™˜ê²½ë³€ìˆ˜
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

# ì „ì—­ ë³€ìˆ˜
_rag_system = None

class RAGSystem:
    def __init__(self, pdf_dir: str = "rag_documents", persist_dir: str = "vectorstore"):
        self.pdf_dir = Path(pdf_dir)
        self.persist_dir = Path(persist_dir)
        
        # Gemini Embeddings API ì‚¬ìš© (ë©”ëª¨ë¦¬ 0MB!)
        print("ğŸ”§ Gemini Embeddings API ì´ˆê¸°í™” ì¤‘...")
        self.embeddings = GoogleGenerativeAIEmbeddings(
            model="models/embedding-001",  # Gemini ì„ë² ë”© ëª¨ë¸
            google_api_key=GOOGLE_API_KEY
        )
        print("âœ… Gemini Embeddings API ì´ˆê¸°í™” ì™„ë£Œ")
        
        # í…ìŠ¤íŠ¸ ë¶„í• ê¸°
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=500,
            chunk_overlap=50,
            separators=["\n\n", "\n", ".", " ", ""]
        )
        
        self.vectorstore = None
    
    def load_pdfs(self) -> List[Dict[str, str]]:
        """PDF íŒŒì¼ë“¤ì„ ì½ì–´ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        documents = []
        
        if not self.pdf_dir.exists():
            print(f"âš ï¸ PDF ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {self.pdf_dir}")
            return documents
        
        pdf_files = list(self.pdf_dir.glob("*.pdf"))
        
        if not pdf_files:
            print(f"âš ï¸ PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {self.pdf_dir}")
            return documents
        
        for pdf_path in pdf_files:
            try:
                with pdfplumber.open(pdf_path) as pdf:
                    text = ""
                    for page in pdf.pages:
                        text += page.extract_text() or ""
                    
                    if text.strip():
                        documents.append({
                            "content": text,
                            "source": pdf_path.name
                        })
                        print(f"âœ… ë¡œë“œ ì™„ë£Œ: {pdf_path.name}")
            
            except Exception as e:
                print(f"âŒ PDF ë¡œë“œ ì‹¤íŒ¨ ({pdf_path.name}): {e}")
        
        return documents
    
    def build_vectorstore(self, force_recreate: bool = False):
        """ë²¡í„° DB ìƒì„± (FAISS + Gemini Embeddings)"""
        
        # PDF ë¡œë“œ
        documents = self.load_pdfs()
        
        if not documents:
            print("âš ï¸ ë¡œë“œí•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. RAG ì—†ì´ ì§„í–‰í•©ë‹ˆë‹¤.")
            return
        
        # í…ìŠ¤íŠ¸ ë¶„í• 
        all_splits = []
        for doc in documents:
            splits = self.text_splitter.split_text(doc["content"])
            for split in splits:
                all_splits.append({
                    "content": split,
                    "source": doc["source"]
                })
        
        print(f"ğŸ“„ ì´ {len(all_splits)}ê°œ ì²­í¬ ìƒì„±")
        
        # ë²¡í„° DB ìƒì„± (FAISS + Gemini Embeddings API)
        texts = [s["content"] for s in all_splits]
        metadatas = [{"source": s["source"]} for s in all_splits]
        
        print("ğŸ”„ ë²¡í„° DB ìƒì„± ì¤‘... (Gemini API í˜¸ì¶œ)")
        self.vectorstore = FAISS.from_texts(
            texts=texts,
            embedding=self.embeddings,  # â† Gemini API ì‚¬ìš©!
            metadatas=metadatas
        )
        
        print(f"âœ… ë²¡í„° DB ìƒì„± ì™„ë£Œ!")
    
    def search(self, query: str, k: int = 3) -> List[Dict[str, str]]:
        """ìœ ì‚¬ë„ ê²€ìƒ‰"""
        if not self.vectorstore:
            return []
        
        try:
            results = self.vectorstore.similarity_search(query, k=k)
            return [
                {
                    "content": doc.page_content,
                    "source": doc.metadata.get("source", "Unknown")
                }
                for doc in results
            ]
        except Exception as e:
            print(f"âŒ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []

# ========================================
# ì „ì—­ í•¨ìˆ˜
# ========================================

def initialize_rag_system(force_recreate: bool = False):
    """RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
    global _rag_system
    
    try:
        _rag_system = RAGSystem()
        _rag_system.build_vectorstore(force_recreate=force_recreate)
        return _rag_system
    except Exception as e:
        print(f"âŒ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        print("âš ï¸ RAG ì—†ì´ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
        return None

def get_rag_system():
    """í˜„ì¬ RAG ì‹œìŠ¤í…œ ë°˜í™˜"""
    return _rag_system