# test_llm.pyë„ ì—…ë°ì´íŠ¸
import asyncio
from dotenv import load_dotenv
from ai_service import classify_symptom, generate_response
from models import ChatRequest

load_dotenv()

async def test_rices():
    print("=" * 50)
    print("ğŸ§ª RICES ê¸°ë°˜ AI ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    # í…ŒìŠ¤íŠ¸ 1: ì˜ë„ ë¶„ë¥˜
    request = ChatRequest(
        message="ì•„ì´ê°€ ì—´ì´ 38ë„ ìˆê³  ê¸°ì¹¨ì„ í•´ìš”",
        user_age=5
    )
    
    intent = await classify_symptom(request)
    print(f"\nâœ… ì˜ë„ ë¶„ë¥˜:\n{intent}")
    
    # í…ŒìŠ¤íŠ¸ 2: ì‘ë‹µ ìƒì„±
    response = await generate_response(
        request=request,
        intent=intent,
        rag_results=[],
        facilities=None
    )
    
    print(f"\nâœ… ì‘ë‹µ:\n{response['response']}")
    print(f"\nâœ… í•µì‹¬ ì¡°ì¹˜:\n{response['key_points']}")

if __name__ == "__main__":
    asyncio.run(test_rices())